{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# dimensions of our images.\n",
    "img_width, img_height = 128, 128\n",
    "\n",
    "train_data_dir = './Open_I_abd_vs_CXRs/TRAIN' # location of training data\n",
    "validation_data_dir = './Open_I_abd_vs_CXRs/VAL' # location of validation data\n",
    "\n",
    "# number of samples used for determining the samples_per_epoch\n",
    "nb_train_samples = 65\n",
    "nb_validation_samples = 10\n",
    "epochs = 10\n",
    "batch_size = 5  \n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255,            # normalize pixel values to [0,1]\n",
    "    shear_range = 0.2,\n",
    "    zoom_range = 0.2,\n",
    "    rotation_range = 20,\n",
    "    width_shift_range = 0.2,\n",
    "    height_shift_range = 0.2,\n",
    "    horizontal_flip = True)\n",
    "val_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255)       # normalize pixel values to [0,1]\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size = (img_height, img_width),\n",
    "    batch_size = batch_size,\n",
    "    class_mode = 'binary')\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size = (img_height, img_width),\n",
    "    batch_size = batch_size,\n",
    "    class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = applications.inception_v3.InceptionV3(weights = 'imagenet', include_top = False, input_shape = (img_width, img_height, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_top = Sequential()\n",
    "model_top.add(GlobalAveragePooling2D(input_shape = base_model.output_shape[1:], data_format = None)),\n",
    "model_top.add(Dense(256, activation = 'relu'))\n",
    "model_top.add(Dropout(0.5))\n",
    "model_top.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "model = Model(inputs = base_model.input, outputs = model_top(base_model.output))\n",
    "\n",
    "model.compile(optimizer = Adam(lr = 0.0001, beta_1 = 0.9, beta_2 = 0.999, epsilon = 1e-08, decay = 0.0),\n",
    "    loss = 'binary_crossentropy',\n",
    "    metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = nb_train_samples // batch_size,\n",
    "    epochs = epochs,\n",
    "    validation_data = validation_generator,\n",
    "    validation_steps = nb_validation_samples // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
